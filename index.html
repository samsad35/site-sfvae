<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title></title>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css"/>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <header>
    <div class="inner-width">
      <h1>LEARNING AND CONTROLLING THE SOURCE-FILTER REPRESENTATION OF SPEECH WITH A VARIATIONAL AUTOENCODER</h1>
      <div class="menu-icon">
        <i class="fas fa-align-right"></i>
      </div>
    </div>
  </header>

  <div class="navigation-menu">
    <nav>
      <li><a href="team.html">Team</a></li>
      <li><a href="#">PHASE RECONSTRUCTION PROBLEM</a></li>
      <li><a href="#">VISUALISATION OF THE LEARNED LATENT SUBSPACES</a></li>
      <li><a href="#">VOWELS GENERATION</a></li>
	  <li><a href="#">CONTROLLING FACTORS OF VARIATION</a></li>
	  <li><a href="#">VOICING AND WHISPERING</a></li>
    </nav>
  </div>
  
	<h1>
		Abstract
	</h1>
  <p>
	  Understanding and controlling latent representations in deep generative models is a challenging yet important problem for analyzing, transforming and generating various types of data.
	  In speech processing, inspiring from the anatomical mechanisms of phonation, the source-filter model considers that speech signals are produced from a few independent and physically meaningful continuous latent factors,
	  among which the fundamental frequency and the formants are of primary importance. In this work, we show that the source-filter model of speech production naturally arises in the latent space of a variational autoencoder (VAE)
	  trained in an unsupervised fashion on a dataset of natural speech signals. Using speech signals generated with an artificial speech synthesizer, we experimentally demonstrate that the fundamental frequency and formant 
	  frequencies are encoded in orthogonal subspaces of the VAE latent space and we develop a weakly-supervised method to accurately and independently control these speech factors of variation within the learned latent subspaces.
	  Without requiring additional information such as text or human-labeled data, we propose a deep generative model of speech spectrograms that is conditioned on the fundamental frequency and formant frequencies,
	  and which is applied to the transformation of speech signals.
  </p>
  
	<h1>
		VOWELS GENERATION
	</h1>
	<p>
	As shown in the following figure, we have developed a graphical interface to generate vowels with the proposed method. The first and second formant frequencies are discriminative features of the vowels, 
	as can be seen from a vowel diagram. In this graphical interface, the values of the frist and second formant frequencies correspond to the y-axis and x-axis respectively, and we can also choose the fundamental frequency in between 100Hz and 300Hz. Given these values, the proposed method generates a speech spectrogram and a time-domain signal is reconstructed with WaveGlow. 
	We provide below examples of generated vowels with different values of the fundamental frequency and first two formant frequencies.
	</p>
	
  <div class="inner-width">
	<iframe src="https://docs.google.com/presentation/d/e/2PACX-1vQfEmH6gZ0fsiMjCaLJmkR09c3E2eW-GefsQWo5NcKAlFWYO_Lt25etYqm3z1UZQq6OlK-DizKcO7c5/embed?start=false&loop=false&delayms=3000" frameborder="0" width="960" height="569" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true">
	</iframe>
  </div>
  
  
  <script>
    $(".menu-icon").click(function(){
      $(this).toggleClass("active");
      $(".navigation-menu").toggleClass("active");
      $(".menu-icon i").toggleClass("fa-times");
    });
  </script>
</body>
</html>